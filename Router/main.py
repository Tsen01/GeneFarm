import os
from fastapi import FastAPI, Request, HTTPException, Body, Query, File, UploadFile, Depends
from pydantic import BaseModel, EmailStr
from fastapi.responses import HTMLResponse, RedirectResponse, JSONResponse
from fastapi.staticfiles import StaticFiles
from fastapi.middleware.cors import CORSMiddleware
from fastapi.templating import Jinja2Templates
from contextlib import asynccontextmanager
from sshtunnel import SSHTunnelForwarder
from pymongo import MongoClient
from typing import Dict, Optional
from dotenv import load_dotenv
from sklearn.metrics import mean_squared_error, mean_absolute_error
import math
import numpy as np
import pandas as pd
import threading
import joblib, torch
from predict import (
    _load_lstm, _load_bilstm,
    multi_step_recursive_predict, multi_step_lr_predict,
    predict_with_lstm, predict_with_bilstm, predict_with_lr
)
from datetime import datetime, timedelta, date
import matplotlib.pyplot as plt
import io, base64
from scipy.optimize import curve_fit
from urllib.parse import quote_plus
from flask import request, jsonify
from scipy.stats import ttest_ind
from statsmodels.stats.multitest import multipletests
from io import BytesIO
from model_def import TabTransformerCLS, EncoderLayerWithAttn
from zoneinfo import ZoneInfo

def logistic_growth(x, K, r, x0):
    return K / (1 + np.exp(-r * (x - x0)))

def safe_float(value):
    try:
        return float(value)
    except (ValueError, TypeError):
        return None

def safe_date(value):
    try:
        return datetime.strptime(value, "%Y-%m-%d")
    except (ValueError, TypeError):
        return None

load_dotenv()

# å…è¨±çš„ä¾†æº
origins = ["http://localhost:8000", "http://127.0.0.1:8000"]

print("SSH_HOST:", os.getenv("SSH_HOST"))
print("MONGO_HOST:", os.getenv("MONGO_HOST"))
print("ALLOWED_ORIGINS:", os.getenv("ALLOWED_ORIGINS"))


# SSH and MongoDB Settings from Environment Variables
SSH_HOST = os.getenv("SSH_HOST")
SSH_PORT = int(os.getenv("SSH_PORT", 22))
SSH_USER = os.getenv("SSH_USER")
SSH_PASSWORD = os.getenv("SSH_PASSWORD")

MONGO_HOST = os.getenv("MONGO_HOST")
MONGO_PORT = int(os.getenv("MONGO_PORT", 27017))
MONGO_USER = os.getenv("MONGO_USER")
MONGO_PASSWORD = os.getenv("MONGO_PASSWORD")
AUTH_DB = os.getenv("AUTH_DB", "admin")
DB_NAME = os.getenv("DB_NAME", "goat_project")

GOAT_COLLECTIONS = ["0007A1", "0007A2", "0007A3", "0007A5", "0007S2Breed"]
SHEEP_COLLECTIONS = [
    "0009-0013A11_MilkAnalysis", "0009-0013A9_Milk", "0009-0013_A4_Kidding",
    "0009-0013_Yean", "S2_Breed", "S7_Sex", "basic", "pubmat"
]

# å…¨åŸŸçš„ MongoDB å®¢æˆ¶ç«¯å’Œ SSH Tunnel
mongo_client = None
ssh_tunnel = None
client_lock = threading.Lock()

# è¼‰å…¥ CSV
df = pd.read_csv("../../weight_prediction_data.csv")

# --------- é€šç”¨è½‰æ›å·¥å…· ---------
def as_float(x):
    # è½‰ç‚º Python floatï¼Œç©ºå€¼/ç„¡æ³•è½‰æ› -> None
    try:
        if x is None:
            return None
        # pandas çš„ NaN
        if isinstance(x, float) and math.isnan(x):
            return None
        if isinstance(x, (np.floating, np.integer, np.number)):
            return float(x)
        # å­—ä¸²ä¹Ÿå˜—è©¦è½‰
        if isinstance(x, str) and x.strip() == "":
            return None
        return float(x)
    except Exception:
        return None

def as_date_str(x):
    # è½‰ç‚º 'YYYY-MM-DD'ï¼›ç„¡æ³•è½‰ -> None
    if x is None:
        return None
    try:
        # ç›´æ¥è™•ç† pandas.Timestamp / numpy.datetime64 / str / int
        dt = pd.to_datetime(x, errors="coerce")
        if pd.isna(dt):
            return None
        # åªè¦æ—¥æœŸï¼ˆå’Œä½  safe_date å°é½Šï¼‰
        return dt.strftime("%Y-%m-%d")
    except Exception:
        return None

def as_str(x):
    # è½‰ç‚º Python strï¼ŒåŒ…å« numpy æ³›å‹ -> .item()
    if x is None:
        return None
    try:
        if isinstance(x, np.generic):
            x = x.item()
        return str(x)
    except Exception:
        return None

# --------- è·¯ç”± ---------

@asynccontextmanager
async def lifespan(app: FastAPI):
    global mongo_client, ssh_tunnel
    try:
        # å»ºç«‹ SSH Tunnel å’Œ MongoDB é€£ç·š
        ssh_tunnel = SSHTunnelForwarder(
            (SSH_HOST, SSH_PORT),
            ssh_username=SSH_USER,
            ssh_password=SSH_PASSWORD,
            remote_bind_address=(MONGO_HOST, MONGO_PORT)
        )
        ssh_tunnel.start()

        mongo_client = MongoClient(
            f"mongodb://{MONGO_USER}:{MONGO_PASSWORD}@127.0.0.1:{ssh_tunnel.local_bind_port}/?authSource={AUTH_DB}"
        )

        app.state.mongo_client = mongo_client
        app.state.ssh_tunnel = ssh_tunnel
        print("ğŸ”— MongoDB é€£ç·šå·²å»ºç«‹")
        yield

    finally:
        # é—œé–‰ MongoDB å’Œ SSH Tunnel é€£ç·š
        if mongo_client is not None:
            mongo_client.close()
            print("ğŸ›‘ MongoDB é€£ç·šå·²é—œé–‰")
        if ssh_tunnel is not None:
            ssh_tunnel.stop()
            print("ğŸ›‘ SSH Tunnel å·²é—œé–‰")

app = FastAPI(lifespan=lifespan)

# å•Ÿå‹•æ™‚è¼‰å…¥æ¨¡å‹
model_data = joblib.load("gene_model.pkl")
svd = model_data["svd"]
scaler = model_data["scaler"]
model = model_data["model"]
gene_names = model_data["gene_names"]

model.eval()  # è¨­æˆæ¨è«–æ¨¡å¼
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)

# é…ç½®æ¨¡æ¿
templates = Jinja2Templates(directory="templates")  # æŒ‡å®š HTML æ¨¡æ¿çš„ç›®éŒ„

# è¨­å®šéœæ…‹æ–‡ä»¶è³‡æ–™å¤¾
base_dir = os.path.dirname(__file__)  # å–å¾— main.py æ‰€åœ¨ç›®éŒ„
static_dir = os.path.join(base_dir, "static")
app.mount("/static", StaticFiles(directory=static_dir), name="static")

# Enable CORS (more secure than allowing all origins)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  
    allow_methods=["*"],
    allow_headers=["*"],
)

from auth import auth_router
app.include_router(auth_router, prefix="/auth", tags=["auth"])

from farm_upload import farm_router
app.include_router(farm_router, prefix="/farm", tags=['farm_upload'])

from gene_upload import gene_router
# è¨»å†Š gene_upload router
app.include_router(gene_router, prefix="/gene", tags=["gene_upload"])

# è·¯ç”±ï¼šé¦–é 
@app.get("/", response_class=HTMLResponse)
async def redirect_to_animal_manager():
    return RedirectResponse("/AnimalManager", status_code=302)

@app.get("/AnimalManager", response_class=HTMLResponse)
async def animal_manager_home(request: Request):
    return templates.TemplateResponse("index2.html", {"request": request})

# è·¯ç”±ï¼šæˆ‘çš„ç‰§å ´
@app.get("/AnimalManager/myfarm", response_class=HTMLResponse)
async def animal_manager_myfarm(request: Request):
    return templates.TemplateResponse("myfarm.html", {"request": request})

@app.get("/AnimalManager/Edit/{collectionName}", response_class=HTMLResponse)
async def animal_manager_myfarm(request: Request):
    return templates.TemplateResponse("EditData.html", {"request": request})

@app.get("/AnimalManager/EditGene/{collectionName}", response_class=HTMLResponse)
async def animal_manager_myfarm(request: Request):
    return templates.TemplateResponse("EditGene.html", {"request": request})

@app.get("/AnimalManager/predict", response_class=HTMLResponse)
async def animal_manager_predict(request: Request):
    return templates.TemplateResponse("predict.html", {"request": request})

@app.get("/AnimalManager/search", response_class=HTMLResponse)
async def animal_manager_search(request: Request):
    return templates.TemplateResponse("search.html", {"request": request})

@app.get("/AnimalManager/gene", response_class=HTMLResponse)
async def animal_manager_gene(request: Request):
    return templates.TemplateResponse("gene.html", {"request": request})

@app.get("/AnimalManager/genePredict", response_class=HTMLResponse)
async def animal_manager_gene(request: Request):
    return templates.TemplateResponse("genePredict.html", {"request": request})

@app.get("/AnimalManager/history", response_class=HTMLResponse)
async def animal_manager_gene(request: Request):
    return templates.TemplateResponse("history.html", {"request": request})


# æ¸¬è©¦æ˜¯å¦æœ‰æˆåŠŸé€£åˆ° MongoDB
@app.get("/test_connection")
async def test_connection():
    try:
        db = mongo_client[DB_NAME]
        db_list = db.list_collection_names()
        return {"status": "success", "collections": db_list}
    except Exception as e:
        return {"status": "error", "message": str(e)}


# è¼‰å…¥è³‡æ–™é›†
client = MongoClient(f"mongodb://{MONGO_USER}:{MONGO_PASSWORD}@localhost:27017/{DB_NAME}?authSource=admin")
db = client[DB_NAME]

from auth import get_current_user

@app.get("/get_collections")
async def get_collections():
    try:
        collections = db.list_collection_names()
        return collections  # æœƒè‡ªå‹•è½‰æˆ JSON
    except Exception as e:
        print(f"ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
        return JSONResponse(status_code=500, content={"error": str(e)})


@app.post("/predict")
def run_prediction(payload: Dict = Body(...), current_user=Depends(get_current_user)):
    db = mongo_client['user_accounts']
    history_collection = db['growth_prediction']
    model_type = payload.get("model_type", "lstm")
    input_data = payload.get("input_data")
    user_id = current_user.get("sub")
    user_name = current_user.get("username")
    user_role = current_user.get("role")

    if not input_data or len(input_data) < 12:
        raise HTTPException(status_code=400, detail="input_data must have at least 12 items")

    try:
        # å‡ºç”Ÿé«”é‡èˆ‡æ—¥æœŸ
        self_birweight = safe_float(input_data[1])
        self_birmeadate = safe_date(input_data[2])

        # æ”¶é›†æ‰€æœ‰æœ‰æ•ˆæ¸¬é‡
        weight_date_pairs = []
        for i in range(3, 13, 2):
            weight = safe_float(input_data[i])
            meadate = safe_date(input_data[i+1])
            if weight is not None and meadate is not None:
                weight_date_pairs.append((meadate, weight))

        if self_birweight is None or self_birmeadate is None:
            raise HTTPException(status_code=400, detail="å‡ºç”Ÿé«”é‡èˆ‡å‡ºç”Ÿæ¸¬é‡æ—¥æœŸç‚ºå¿…å¡«")
        if len(weight_date_pairs) == 0:
            raise HTTPException(status_code=400, detail="è‡³å°‘è¦æœ‰ä¸€ç­†æœ‰æ•ˆçš„æ¸¬é‡è³‡æ–™")

        weight_date_pairs.sort(key=lambda x: x[0])
        dates = [d for d, _ in weight_date_pairs]
        days_since_birth = [(d - self_birmeadate).days for d in dates]
        weights = [w for _, w in weight_date_pairs]

        # é æ¸¬å¤©æ•¸
        try:
            predict_days = int(input_data[18].strip())
        except (IndexError, ValueError, AttributeError):
            predict_days = 30

        if predict_days <= 0:
            raise HTTPException(status_code=400, detail="é æ¸¬å¤©æ•¸å¿…é ˆå¤§æ–¼ 0")

        # === æº–å‚™è¼¸å…¥çµ¦ LSTM ===
        seq_data = []
        for i in range(3, 13, 2):
            weight = safe_float(input_data[i])
            mea_date = safe_date(input_data[i+1])
            if weight is not None and mea_date is not None:
                days = (mea_date - self_birmeadate).days
                if days >= 0:
                    seq_data.append([weight, days])
        seq_data = seq_data[-4:]
        while len(seq_data) < 4:
            seq_data.insert(0, [0.0, 0.0])
        X_seq = np.array([seq_data], dtype=np.float32)

        # è®€å– breed mapping & lifespan
        breed_info = joblib.load("../breed_info_BiLSTM_Mapping.pkl")
        breed_mapping = breed_info['mapping']
        breed_lifespan = breed_info['lifespan']

        # å…ˆè¨˜ä¸‹æ‰€æœ‰åŸå§‹æ¬„ä½åï¼Œé¿å…åœ¨è¿­ä»£æ™‚å‹•æ…‹æ”¹å­—å…¸
        original_cols = list(breed_mapping.keys())

        # å…ˆå»ºç«‹åå‘ mapping
        for col in original_cols:
            if not col.endswith("_reverse"):
                breed_mapping[f"{col}_reverse"] = {v: k for k, v in breed_mapping[col].items()}

        # ç¾åœ¨å†æª¢æŸ¥ mappingï¼ˆæ­£å‘ & åå‘éƒ½æœƒæœ‰ï¼‰
        for col in breed_mapping:
            print(f"{col} çš„ mappingï¼š")
            print(breed_mapping[col])
        print("-" * 40)

        # ç·¨ç¢¼å‡½å¼
        def encode_breed(breed, field_name):
            return breed_mapping.get(f"{field_name}_reverse", {}).get(breed, 0)


        self_breed = encode_breed(input_data[13], 'self_Breed')
        dam_breed = encode_breed(input_data[15], 'dam_Breed')
        sire_breed = encode_breed(input_data[17], 'sire_Breed')

        # å¦‚æœè¦æ‰¾åç¨±ï¼Œç›´æ¥ç”¨åŸ mapping (æ•¸å­— -> åç¨±)
        self_breed_name = breed_mapping['self_Breed_reverse'].get(self_breed, 'Unknown')

        # å–æœ€å¾Œä¸€ç­†æ¸¬é‡æ—¥æœŸï¼Œå¦‚æœæ²’æœ‰å°±ç”¨å‡ºç”Ÿæ—¥æœŸ
        last_mea_date = dates[-1] if len(dates) > 0 else self_birmeadate

        # é æ¸¬ç›®æ¨™æ—¥æœŸ = æœ€å¾Œæ¸¬é‡æ—¥æœŸ + é æ¸¬å¤©æ•¸
        target_date = last_mea_date + timedelta(days=predict_days)

        # è¨ˆç®—è·é›¢å‡ºç”Ÿçš„ç¸½å¤©æ•¸ï¼ˆç”¨æ–¼ log èˆ‡ age_ratioï¼‰
        total_days_from_birth = (target_date - self_birmeadate).days
        log_predict_days = math.log(total_days_from_birth + 1)

        # è¨ˆç®—å¹´é½¡æ¯”ä¾‹
        max_life_days = breed_lifespan.get(self_breed_name, 365 * 10)
        age_ratio = total_days_from_birth / max_life_days
        max_weight = 90.0

        # åªç”¨ weightï¼Œä¸ç”¨ days
        flat_seq = [w for w, d in seq_data]  # 3 ç¶­
        Regression_static_feat = [log_predict_days, age_ratio]  # 2 ç¶­
        X_lr = np.array([flat_seq + Regression_static_feat], dtype=np.float32)  # ç¸½å…± 5 ç¶­

        # éœæ…‹ç‰¹å¾µ
        static_feat = [self_breed, dam_breed, sire_breed, log_predict_days, age_ratio, max_weight]

        # é€™è£¡åªéœ€è¦å‘¼å«ï¼Œä¸éœ€è¦å†å®šç¾©å‡½æ•¸
        att_model = _load_lstm()
        bilstm_model = _load_bilstm()
        # æŠŠæœ€å¾ŒçœŸå¯¦é»æ¥ä¸Šå»
        last_day = last_mea_date
        last_weight = weights[-1]

        # æœ‰Attentionçš„Bi-LSTM
        lstm_preds, lstm_dates = multi_step_recursive_predict(att_model, X_seq[0].tolist(), static_feat,
                                                            self_birmeadate, self_breed_name, breed_lifespan, last_real_weight=last_weight, last_mea_date = last_day)
        # æ²’æœ‰Attentionçš„Bi-LSTM
        bilstm_preds, bilstm_dates = multi_step_recursive_predict(bilstm_model, X_seq[0].tolist(), static_feat,
                                                                self_birmeadate, self_breed_name, breed_lifespan, last_real_weight=last_weight, last_mea_date = last_day)
        lr_preds, lr_dates = multi_step_lr_predict(list(flat_seq), static_feat,
                                                self_birmeadate, self_breed_name, breed_lifespan, last_real_weight=last_weight, last_mea_date = last_day)

        # æŠŠæ—¥æœŸè½‰æˆè·å‡ºç”Ÿçš„å¤©æ•¸
        lstm_days = [(d - self_birmeadate).days for d in lstm_dates]
        bilstm_days = [(d - self_birmeadate).days for d in bilstm_dates]
        lr_days = [(d - self_birmeadate).days for d in lr_dates]

    except Exception as e:
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=400, detail=f"Prediction error: {str(e)}")

    def to_native(x):
        if isinstance(x, np.generic):
            return x.item()
        if isinstance(x, (pd.Timestamp, datetime, date)):
            return x.isoformat()
        return x
    
    # --- å¦‚æœå‰ç«¯/è³‡æ–™æœ‰ã€Œå¯¦éš›çš„æœªä¾†é»ã€ï¼Œè©¦è‘—å°é½Šè¨ˆç®— metrics ---
    # ä¾‹å¦‚ weight_date_pairs ä¸­è‹¥åŒ…å«å·²ä¾†åˆ°æœªä¾†æ™‚é–“çš„å¯¦æ¸¬é»ï¼ˆdates > last_mea_dateï¼‰ï¼Œå°±æ‹¿ä¾†æ¯”å°
    actuals_by_date = {d.date(): w for d, w in weight_date_pairs}  # åŸå…ˆæ”¶é›†åˆ°çš„æ‰€æœ‰é»ï¼ˆé€šå¸¸åªæœ‰éå»ï¼‰
    actual_series = [{"date": d.isoformat(), "weight": float(w)} for d, w in weight_date_pairs]
    print("æ‰€æœ‰å¯¦éš›é»ï¼š", actuals_by_date)
    # å¦‚æœä½ å‰ç«¯æœƒå‚³æ›´å¤šæœªä¾†çœŸå¯¦å€¼åˆ° input_dataï¼Œæˆ‘å€‘è¦æŠŠå®ƒå€‘ä¹Ÿå¡é€² weight_date_pairs æ‰æœƒè¢«ä½¿ç”¨
    
        # === è©•ä¼°æŒ‡æ¨™ (æ”¹ç‚ºå–®æ­¥é æ¸¬) ===
    def compute_single_step_metrics(weight_date_pairs, inputs):
        y_true, y_pred = [], []

        for (d, w) in weight_date_pairs:
            lstm_p = predict_with_lstm(inputs["X_seq"], inputs["static_feat"])
            bilstm_p = predict_with_bilstm(inputs["X_seq"], inputs["static_feat"])
            lr_p = predict_with_lr(inputs["flat_seq"], inputs["log_predict_days"], inputs["age_ratio"])

            y_true.append(float(w))
            y_pred.append({
                "Bilstm_attention": lstm_p,
                "Bilstm_no_attention": bilstm_p,
                "linear_regression": lr_p
            })

        # é€æ¨¡å‹è¨ˆç®—èª¤å·®
        metrics = {}
        for model_name in ["Bilstm_attention", "Bilstm_no_attention", "linear_regression"]:
            preds = [p[model_name] for p in y_pred]
            mse_v = float(mean_squared_error(y_true, preds))
            mae_v = float(mean_absolute_error(y_true, preds))
            rmse_v = float(np.sqrt(mse_v))
            metrics[model_name] = {
                "MSE": mse_v,
                "MAE": mae_v,
                "RMSE": rmse_v,
                "n_points_used": len(y_true)
            }

        return metrics

    model_inputs = {
        "X_seq": X_seq[0].tolist(), # shape (4, 2) æœ€è¿‘4å¤©çš„åºåˆ—ç‰¹å¾µ
        "static_feat": static_feat, # shape (6,) éœæ…‹ç‰¹å¾µ
        "flat_seq": flat_seq,       # æ”¤å¹³æˆä¸€ç¶­çš„åºåˆ—è³‡æ–™ (çµ¦LRç”¨)
        "log_predict_days": log_predict_days, # æ¯ç­†å°æ‡‰çš„ log(days)
        "age_ratio": age_ratio      # æ¯ç­†å°æ‡‰çš„ age_ratio
    }
    # --- è©•ä¼°æŒ‡æ¨™ ---
    metrics = compute_single_step_metrics(weight_date_pairs, model_inputs) # weight_date_pairs = [(datetime, weight), ...]
    
    # ---- æ›´æ–° recordï¼šæŠŠ preds è½‰æˆç´” Python list (float)ï¼Œä¸¦å¦å¤–å­˜ last_value ----
    def to_float_list(arr):
        # å°‡å¯èƒ½ç‚º numpy array / list / tuple çš„ preds è½‰ç‚º list of native floats
        return [float(x) for x in (np.asarray(arr).ravel().tolist())]

    lstm_preds_list = to_float_list(lstm_preds)
    bilstm_preds_list = to_float_list(bilstm_preds)
    lr_preds_list = to_float_list(lr_preds)

    record = {
        "model": model_type,
        "earnum": to_native(input_data[0]),
        # å„²å­˜æ•´æ®µé æ¸¬ï¼ˆlistï¼‰
        "lstm_prediction_series": lstm_preds_list,
        "bilstm_prediction_series": bilstm_preds_list,
        "linear_regression_series": lr_preds_list,
        "metrics": metrics,
        # å„²å­˜ summary scalarï¼ˆä¾‹å¦‚æœ€å¾Œä¸€å€‹é æ¸¬å€¼ï¼‰
        "lstm_prediction_last": lstm_preds_list[-1] if len(lstm_preds_list) > 0 else None,
        "bilstm_prediction_last": bilstm_preds_list[-1] if len(bilstm_preds_list) > 0 else None,
        "linear_regression_last": lr_preds_list[-1] if len(lr_preds_list) > 0 else None,
        "user_id": user_id,
        "user_name": user_name,
        "user_role": user_role,
        "timestamp": datetime.now()
    }
    history_collection.insert_one(record)

    # --- å›å‚³ JSON ---
    result_payload = {
        "model": model_type,
        "earnum": to_native(input_data[0]),
        "predictions": {
            "Bi-LSTM_Attention": [{"date": d.isoformat(), "days": (d - self_birmeadate).days, "weight": float(w)} for d,w in zip(lstm_dates, lstm_preds)],
            "Bi-LSTM_no_Attention": [{"date": d.isoformat(), "days": (d - self_birmeadate).days, "weight": float(w)} for d,w in zip(bilstm_dates, bilstm_preds)],
            "Linear_Regression": [{"date": d.isoformat(), "days": (d - self_birmeadate).days, "weight": float(w)} for d,w in zip(lr_dates, lr_preds)]
        },
        "metrics": metrics,
        "actual": actual_series
        # "growth_curve_base64": growth_curve_base64
    }

    return result_payload

@app.get("/get_sheep_list")
def get_sheep_list():
    # å…¨éƒ¨è½‰æˆå­—ä¸²ï¼Œé¿å… numpy å‹åˆ¥æ··å…¥
    ids = df["self_EarNum"].dropna().astype(str).unique().tolist()
    return JSONResponse(content=ids)

@app.get("/get_sheep_data")
def get_sheep_data(earnum: str = Query(...), current_user = Depends(get_current_user)):
    # ä»¥å­—ä¸²æ¯”å°ï¼Œé¿å… df è£¡æ˜¯æ•¸å­—å‹åˆ¥æ™‚æ¯”å°å¤±æ•—
    rows = df
    rows = rows[rows["self_EarNum"].astype(str) == str(earnum)].sort_values(by="self_MeaDate")
    if rows.empty:
        raise HTTPException(status_code=404, detail="Ear number not found")

    # å–ç¬¬ä¸€åˆ—ç•¶å…¶ä»–æ¬„ä½ä¾†æº
    row = rows.iloc[0]

    # å–å‰ 5 ç­† (weight, date)ï¼Œä¸è¶³è£œ None
    # æ³¨æ„é †åºï¼šä½ çš„ /predict è®€çš„æ˜¯ weight åœ¨å‰ã€date åœ¨å¾Œ
    pairs = rows[["self_Weight", "self_MeaDate"]].head(5).values.tolist()
    while len(pairs) < 5:
        pairs.append([None, None])

    # æ”¤å¹³æˆ [w1, d1, w2, d2, ...]
    flat_pairs = []
    for w, d in pairs:
        flat_pairs.append(as_float(w))
        flat_pairs.append(as_date_str(d))

    # å»ºæ§‹ input_dataï¼ˆå›ºå®šé•·åº¦èˆ‡ç´¢å¼•ä½ç½®ï¼‰
    input_data = [
        as_str(row.get("self_EarNum")),          # 0
        as_float(row.get("self_BirWeight")),     # 1
        as_date_str(row.get("self_MeaDate")),    # 2 é€™è£¡è‹¥ä½ æœ‰å‡ºç”Ÿæ—¥æœŸæ¬„ï¼Œæ”¹æˆé‚£å€‹æ¬„ä½
        *flat_pairs,                             # 3..12 (5 çµ„)
        as_str(row.get("self_Breed")),           # 13
        as_str(row.get("dam_EarNum")),           # 14
        as_str(row.get("dam_Breed")),            # 15
        as_str(row.get("sire_EarNum")),          # 16
        as_str(row.get("sire_Breed")),           # 17
        # ä¸æä¾› 18ï¼ˆpredict_daysï¼‰ï¼Œ/predict æœƒ fallback = 30
    ]

    # ç”¨ JSONResponseï¼Œç¢ºä¿æ˜¯ç´” JSON åºåˆ—åŒ–
    return JSONResponse(content=input_data)

@app.post("/genePredict")
async def upload_csv(file: UploadFile = File(...), current_user = Depends(get_current_user)):
    db = mongo_client['user_accounts']
    history_collection = db['gene_prediction']
    user_id = current_user.get("sub")
    user_name = current_user.get("username")
    user_role = current_user.get("role")
    # ç”¨ FastAPI æä¾›çš„ UploadFile è®€æª”æ¡ˆ
    df = pd.read_csv(file.file)

    # ========= ä½ çš„åˆ†ææµç¨‹ =========
    df = df[['ID', 'C1', 'C2', 'C3', 'C4', 'C5', 'C6']]
    df['ID'] = df['ID'].astype(str).str.strip()
    df.set_index('ID', inplace=True)

    group1 = ['C1', 'C2', 'C3']
    group0 = ['C4', 'C5', 'C6']
    
    expr = df[group1 + group0]
    keep = (expr >= 1).sum(axis=1) >= 2
    df_f = df.loc[keep]

    log2fc = np.log2(df_f[group1].mean(axis=1) + 1) - np.log2(df_f[group0].mean(axis=1) + 1)
    t_stat, pval = ttest_ind(df_f[group1].T, df_f[group0].T, axis=0, equal_var=False)
    rej, qval, _, _ = multipletests(pval, method='fdr_bh')

    sig = (np.abs(log2fc) > 1) & (qval < 0.05)
    sig_genes = df_f.index[sig]

    # ç«å±±åœ–
    # plt.figure(figsize=(6, 5))
    # plt.scatter(log2fc, -np.log10(pval), c='gray', alpha=0.5, s=10)
    # plt.scatter(log2fc[sig], -np.log10(pval[sig]), c='red', s=10)
    # plt.axvline(x=1, color='purple', linestyle='--', label = "2X higher in high fertility")
    # plt.axvline(x=-1, color='blue', linestyle='--', label = "2X lower in low fertility")
    # plt.axhline(y=-np.log10(0.05), color='green', linestyle='--', label = "p_value threshold")
    # plt.xlabel("ç¹æ®–ç‡çµ„åŸºå› è¡¨é”(high fertility v.s low fertility)")
    # plt.ylabel("é¡¯è‘—æ€§(p_value)")
    # plt.title("Volcano Plot")
    # plt.legend(loc="upper left")   # <<< åŠ é€™å€‹æ‰æœƒé¡¯ç¤º label

    # buf = BytesIO()
    # plt.savefig(buf, format="png")
    # buf.seek(0)
    # img_base64 = base64.b64encode(buf.read()).decode("utf-8")
    # plt.close()

    # å»ºç«‹çµæœ DataFrameï¼ˆçµ¦ç«å±±åœ–ï¼‰
    results_df = pd.DataFrame({
        "gene": df_f.index,
        "log2FC": log2fc,
        "pval": pval,
        "qval": qval,
        "negLog10P": -np.log10(pval),
        "significant": sig
    })

    # æº–å‚™ Highcharts ç”¨çš„è³‡æ–™
    volcano_data = [
        {
            "gene": row['gene'],
            "x": float(row['log2FC']),
            "y": float(row['negLog10P']),
            "significant": bool(row['significant'])
        }
        for _, row in results_df.iterrows()
    ]

    # --- å¦‚æœæ²’æœ‰é¡¯è‘—åŸºå› ï¼Œç›´æ¥å›å‚³ ---
    if len(sig_genes) == 0:
        return {
            "sig_gene_count": 0,
            "top_genes": [],
            "volcano_data": volcano_data
        }

    # ä¿ç•™é¡¯è‘—åŸºå› è¡¨é”å€¼
    X_filtered = expr.loc[sig_genes].values.T  # (samples, genes)
    X_reduced = svd.transform(X_filtered)      # SVD é™ç¶­
    X_scaled = scaler.transform(X_reduced)

    X_tensor = torch.tensor(X_scaled, dtype=torch.float32).to(device)
    with torch.no_grad():
        _ = model(X_tensor, capture_attn=True)
        attn = model.last_attn  # (B, H, L, L)

    # CLS -> ç‰¹å¾µæ³¨æ„åŠ›
    cls2feat = attn[:, :, 0, 1:]  # (B, H, F)
    comp_importance = cls2feat.mean(dim=(0, 1)).cpu().numpy()
    comp_importance /= comp_importance.sum() + 1e-12

    # SVD åˆ†é‡æ˜ å°„å›åŸºå› 
    Vt = svd.components_  # (n_components, n_genes)
    gene_importance = np.abs(comp_importance[:, None] * Vt).sum(axis=0)

    # 1) å»ºç«‹ mapping ä¸¦å– log2fc_filtered
    log2fc_map = dict(zip(sig_genes, log2fc))
    log2fc_filtered = np.array([log2fc_map.get(g, np.nan) for g in sig_genes])

    # 2) ç§»é™¤ missing
    valid_mask = ~np.isnan(log2fc_filtered)
    gene_names = np.array(sig_genes)[valid_mask]
    gene_importance = np.array(gene_importance)[valid_mask]
    log2fc_filtered = log2fc_filtered[valid_mask]

    # 3) åˆ†æˆé«˜ã€ä½ç¹æ®–ç‡
    mask_high = log2fc_filtered > 0
    mask_low  = log2fc_filtered < 0

    # é«˜ç¹æ®–ç‡ top10
    idx_high = np.argsort(-gene_importance[mask_high])[:10]
    top_high = [
        {"gene": g, "score": float(s), "log2FC": float(fc)}
        for g, s, fc in zip(
            gene_names[mask_high][idx_high],
            gene_importance[mask_high][idx_high],
            log2fc_filtered[mask_high][idx_high]
        )
    ]

    # ä½ç¹æ®–ç‡ top10
    idx_low = np.argsort(-gene_importance[mask_low])[:10]
    top_low = [
        {"gene": g, "score": float(s), "log2FC": float(fc)}
        for g, s, fc in zip(
            gene_names[mask_low][idx_low],
            gene_importance[mask_low][idx_low],
            log2fc_filtered[mask_low][idx_low]
        )
    ]

    record = {
        "timestamp": datetime.now(),
        "sig_gene_count": len(sig_genes),
        "top_high_genes": top_high,
        "top_low_genes": top_low,
        "user_id": user_id,
        "user_name": user_name,
        "user_role": user_role
    }

    history_collection.insert_one(record)

    # å­˜å…¥è³‡æ–™åº«
    # history_collection.insert_one({
    #     "timestamp": datetime.now(),
    #     **record
    # })

    # å›å‚³ API
    return {
        "sig_gene_count": len(sig_genes),
        "top_high_genes": top_high,
        "top_low_genes": top_low,
        "volcano_data": volcano_data
    }

@app.post("/get_personal_data")
async def get_personal_data(
    request: Request,
    current_user=Depends(get_current_user)
):
    # current_user å¾ token è§£å‡ºä¾†
    user_id = current_user.get("sub")
    role = current_user.get("role")

    if not user_id or not role:
        raise HTTPException(status_code=400, detail="ä½¿ç”¨è€…è³‡æ–™ä¸å®Œæ•´")

    # æ ¹æ“šè§’è‰²é¸æ“‡è³‡æ–™åº«
    db = mongo_client['user_accounts']
    if role == "Farmer":
        collection = db['growth_prediction']
    elif role == "GeneticResearcher":
        collection = db['gene_prediction']
    else:
        raise HTTPException(status_code=400, detail="è§’è‰²éŒ¯èª¤")

    # å¾è³‡æ–™åº«éæ¿¾ user_id
    data_cursor = collection.find({"user_id": user_id}, {"_id": 0})
    data = list(data_cursor)

    if not data:
        raise HTTPException(status_code=404, detail="æ‰¾ä¸åˆ°æ­·å²è³‡æ–™")

    return {"data": data}